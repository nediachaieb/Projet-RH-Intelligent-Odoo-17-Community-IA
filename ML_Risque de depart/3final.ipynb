{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install xgboost scikit-learn imbalanced-learn shap matplotlib seaborn pandas optuna joblib"
   ],
   "metadata": {
    "id": "e84pCuUBTdcs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750545221809,
     "user_tz": -60,
     "elapsed": 5886,
     "user": {
      "displayName": "nedia chaieb",
      "userId": "02418120950381189238"
     }
    },
    "outputId": "93fb1168-4242-4d11-8d04-80d7345ddf55"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
      "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder,\n",
    "    OrdinalEncoder, LabelEncoder\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR     = Path(\"/home/nada/Project_odoo_17_IA-main/ML_Risque de depart\")\n",
    "TRAIN_PATH   = DATA_DIR / \"train_with_risk.csv\"\n",
    "TEST_PATH    = DATA_DIR / \"test_with_predictions.csv\"\n",
    "OUTPUT_DIR   = DATA_DIR / \"model\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Définition des colonnes ordinales\n",
    "ORDINAL_MAP = {\n",
    "    'work_life_balance':    ['Poor', 'Fair', 'Good', 'Excellent'],\n",
    "    'job_satisfaction':     ['Low', 'Medium', 'High', 'Very High'],\n",
    "    'performance_rating':   ['Low', 'Below Average', 'Average', 'High'],\n",
    "    'employee_recognition': ['Low', 'Medium', 'High', 'Very High'],\n",
    "    'company_reputation':   ['Poor', 'Fair', 'Good', 'Excellent']\n",
    "}\n",
    "\n",
    "def load_data(path):\n",
    "    print(f\" Chargement des données depuis {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    # nettoyage des noms de colonnes pour obtenir du snake_case\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "          .str.strip()\n",
    "          .str.lower()\n",
    "          .str.replace(\" \", \"_\")\n",
    "          .str.replace(\"-\", \"_\")\n",
    "    )\n",
    "    print(f\" {len(df)} lignes chargées, colonnes nettoyées\")\n",
    "    return df\n",
    "\n",
    "def validate_ordinal_columns(df, ordinal_map):\n",
    "    print(\"Validation des colonnes ordinales\")\n",
    "    for col, cats in ordinal_map.items():\n",
    "        if col in df.columns:\n",
    "            invalid = set(df[col].dropna()) - set(cats)\n",
    "            if invalid:\n",
    "                raise ValueError(f\"Colonne {col} contient des valeurs inattendues : {invalid}\")\n",
    "    print(\" Toutes les valeurs ordinales sont conformes\")\n",
    "\n",
    "def preprocess_data(train_df, ordinal_map):\n",
    "    print(\"  Prétraitement des données\")\n",
    "    validate_ordinal_columns(train_df, ordinal_map)\n",
    "\n",
    "    # Label encoding de la cible Risk_Level\n",
    "    print(\"Encodage de la cible 'risk_level'\")\n",
    "    le = LabelEncoder()\n",
    "    le.classes_ = np.array(['Low', 'Medium', 'High'])  # fixe l’ordre 0 pour low\n",
    "    y = le.transform(train_df['risk_level'])\n",
    "    print(f\"Mapping cible : {list(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "    # Nettoyage des colonnes inutiles\n",
    "    drop_cols = [\n",
    "        'employee_id', 'attrition', 'attrition_binary',\n",
    "        'risk_score', 'risk_level'\n",
    "    ]\n",
    "    X = train_df.drop(columns=[c for c in drop_cols if c in train_df.columns])\n",
    "    print(f\" Colonn es supprimées : {drop_cols}\")\n",
    "\n",
    "    # Définition des types de colonnes pour le préprocesseur\n",
    "    ordinal_cols = list(ordinal_map.keys())\n",
    "    num_cols     = [\n",
    "        'age', 'years_at_company', 'monthly_income',\n",
    "        'distance_from_home', 'number_of_promotions',\n",
    "        'number_of_dependents'\n",
    "    ]\n",
    "    cat_cols     = [\n",
    "        'job_role', 'job_level', 'company_size', 'education_level',\n",
    "        'marital_status', 'overtime', 'remote_work',\n",
    "        'leadership_opportunities', 'innovation_opportunities',\n",
    "        'gender'\n",
    "    ]\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('ord', OrdinalEncoder(categories=[ordinal_map[c] for c in ordinal_cols]), ordinal_cols),\n",
    "        ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols),\n",
    "    ])\n",
    "    print(\" Préprocesseur configuré (numéral, ordinal, one-hot)\")\n",
    "\n",
    "    return X, y, preprocessor, le\n",
    "\n",
    "def tune_xgboost(X, y, preprocessor, n_trials=50):\n",
    "    print(f\" Lancement de l’optimisation Optuna ({n_trials} essais)…\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'objective': 'multi:softprob',\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'use_label_encoder': False,\n",
    "\n",
    "        }\n",
    "        # Utilisation d’ImbPipeline pour supporter SMOTE\n",
    "        pipeline = ImbPipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('clf', XGBClassifier(**params))\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "        score = cross_val_score(pipeline, X, y, scoring='f1_macro', cv=cv).mean()\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(\" Optimisation terminée\")\n",
    "    print(f\" Meilleurs paramètres : {study.best_params}\")\n",
    "    return study.best_params\n",
    "\n",
    "def train_model(X, y, preprocessor, best_params):\n",
    "    print(\"  Entraînement du modèle avec SMOTE\")\n",
    "    # 1) Fit du préprocesseur\n",
    "    X_proc = preprocessor.fit_transform(X)\n",
    "    print(\"  Préprocesseur ajusté\")\n",
    "\n",
    "    # 2) SMOTE pour l’entraînement\n",
    "    X_res, y_res = SMOTE(random_state=RANDOM_STATE).fit_resample(X_proc, y)\n",
    "    print(f\"   • Après SMOTE : {len(X_res)} échantillons\")\n",
    "\n",
    "    # 3) Entraînement du XGBClassifier\n",
    "    clf = XGBClassifier(\n",
    "        **best_params,\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=RANDOM_STATE,\n",
    "        use_label_encoder=False,\n",
    "\n",
    "    )\n",
    "    clf.fit(X_res, y_res)\n",
    "    print(\"   • Classifieur entraîné\")\n",
    "\n",
    "    # 4) Pipeline d’inférence (sans SMOTE)\n",
    "    inference_pipeline = Pipeline([\n",
    "        ('prep', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    print(\" Pipeline d’inférence prêt\")\n",
    "\n",
    "    return inference_pipeline\n",
    "#une évaluation détaillée du modèle\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "def evaluate_model(pipeline, X, y, label_encoder):\n",
    "    print(\"\\n📊 Évaluation du modèle sur l'ensemble d'entraînement complet\")\n",
    "    y_pred = pipeline.predict(X)\n",
    "\n",
    "    print(classification_report(y, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    report = classification_report(y, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results = {\n",
    "        'Modèle': 'XGBoost_Optuna',\n",
    "        'F1_macro': round(f1_score(y, y_pred, average='macro'), 3),\n",
    "        'Accuracy': round(accuracy_score(y, y_pred), 3),\n",
    "        'Precision': round(precision_score(y, y_pred, average='macro'), 3),\n",
    "        'Recall': round(recall_score(y, y_pred, average='macro'), 3),\n",
    "        'F1_Low': round(report['0']['f1-score'], 3),\n",
    "        'F1_Medium': round(report['1']['f1-score'], 3),\n",
    "        'F1_High': round(report['2']['f1-score'], 3),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def save_pipeline_and_encoder(pipeline, encoder):\n",
    "    print(f\"Sauvegarde du pipeline et de l’encodeur dans {OUTPUT_DIR}\")\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(pipeline, OUTPUT_DIR / \"final_model.pkl\")\n",
    "    joblib.dump(encoder,  OUTPUT_DIR / \"label_encoder.pkl\")\n",
    "    print(\" Sauvegarde terminée\")\n",
    "\n",
    "def main():\n",
    "    print(\" Démarrage du script d’entraînement\")\n",
    "    train_df = load_data(TRAIN_PATH)\n",
    "\n",
    "    X, y, preprocessor, le = preprocess_data(train_df, ORDINAL_MAP)\n",
    "    best_params      = tune_xgboost(X, y, preprocessor, n_trials=50)\n",
    "    inference_pipe   = train_model(X, y, preprocessor, best_params)\n",
    "    save_pipeline_and_encoder(inference_pipe, le)\n",
    "    results = evaluate_model(inference_pipe, X, y, le)\n",
    "\n",
    "    # Sauvegarde dans un fichier CSV\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_path = OUTPUT_DIR / \"resultats_xgboost_optuna.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\n Résultats de performance sauvegardés dans : {results_path}\")\n",
    "\n",
    "    print(\"Tout est terminé !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJxrmMHoumCv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750552842266,
     "user_tz": -60,
     "elapsed": 5243250,
     "user": {
      "displayName": "nedia chaieb",
      "userId": "02418120950381189238"
     }
    },
    "outputId": "674e5914-3bd4-45cd-e0de-b4713a647869"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Démarrage du script d’entraînement\n",
      " Chargement des données depuis /content/drive/MyDrive/final_travail_Attrition/train_with_risk.csv\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-06-21 23:13:19,610] A new study created in memory with name: no-name-9b6dfad4-8d83-4e5c-a531-2158b2d8731d\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 59598 lignes chargées, colonnes nettoyées\n",
      "  Prétraitement des données\n",
      "Validation des colonnes ordinales\n",
      " Toutes les valeurs ordinales sont conformes\n",
      "Encodage de la cible 'risk_level'\n",
      "Mapping cible : [(np.str_('Low'), np.int64(0)), (np.str_('Medium'), np.int64(1)), (np.str_('High'), np.int64(2))]\n",
      " Colonn es supprimées : ['employee_id', 'attrition', 'attrition_binary', 'risk_score', 'risk_level']\n",
      " Préprocesseur configuré (numéral, ordinal, one-hot)\n",
      " Lancement de l’optimisation Optuna (50 essais)…\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-06-21 23:14:41,068] Trial 0 finished with value: 0.9467530028560421 and parameters: {'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.108415554974834, 'subsample': 0.8144508285531676, 'colsample_bytree': 0.542326682425544, 'gamma': 3.8884209538222714}. Best is trial 0 with value: 0.9467530028560421.\n",
      "[I 2025-06-21 23:16:11,749] Trial 1 finished with value: 0.9541530755090607 and parameters: {'n_estimators': 322, 'max_depth': 10, 'learning_rate': 0.2448514987917685, 'subsample': 0.7864809793808938, 'colsample_bytree': 0.9031930626295565, 'gamma': 2.8277719187149404}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:17:16,234] Trial 2 finished with value: 0.9456766439786707 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.23586040350611556, 'subsample': 0.8465624764701144, 'colsample_bytree': 0.7393433208160294, 'gamma': 4.949008729467493}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:18:08,164] Trial 3 finished with value: 0.9459815957230256 and parameters: {'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.26486649786652483, 'subsample': 0.9272595476241262, 'colsample_bytree': 0.5494485013691945, 'gamma': 3.549523633834996}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:19:48,120] Trial 4 finished with value: 0.9539355770227796 and parameters: {'n_estimators': 476, 'max_depth': 5, 'learning_rate': 0.12479977845204152, 'subsample': 0.6284632803945234, 'colsample_bytree': 0.5672495086754098, 'gamma': 4.849522513020509}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:23:20,018] Trial 5 finished with value: 0.9472102465872609 and parameters: {'n_estimators': 479, 'max_depth': 10, 'learning_rate': 0.178170296278105, 'subsample': 0.5652121003185339, 'colsample_bytree': 0.5130881282804488, 'gamma': 0.21653265467488136}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:24:14,835] Trial 6 finished with value: 0.9464752313904485 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.20171091713109507, 'subsample': 0.7492148972167203, 'colsample_bytree': 0.5535619977827522, 'gamma': 2.363965798196341}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:25:17,870] Trial 7 finished with value: 0.9486416111813764 and parameters: {'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.17421774841872026, 'subsample': 0.7989708633478046, 'colsample_bytree': 0.5593402881649201, 'gamma': 4.361832768908468}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:26:25,902] Trial 8 finished with value: 0.8982375184451794 and parameters: {'n_estimators': 299, 'max_depth': 3, 'learning_rate': 0.06624967325823362, 'subsample': 0.8591209767651943, 'colsample_bytree': 0.6050006379593795, 'gamma': 0.0554921307161893}. Best is trial 1 with value: 0.9541530755090607.\n",
      "[I 2025-06-21 23:28:48,847] Trial 9 finished with value: 0.9557150838577367 and parameters: {'n_estimators': 434, 'max_depth': 5, 'learning_rate': 0.1386752642321732, 'subsample': 0.6181929509039867, 'colsample_bytree': 0.780207992064621, 'gamma': 0.23665587411249522}. Best is trial 9 with value: 0.9557150838577367.\n",
      "[I 2025-06-21 23:33:32,101] Trial 10 finished with value: 0.9159331939052414 and parameters: {'n_estimators': 395, 'max_depth': 8, 'learning_rate': 0.01806107641874069, 'subsample': 0.6252689125349761, 'colsample_bytree': 0.9885009782267487, 'gamma': 1.185700558674846}. Best is trial 9 with value: 0.9557150838577367.\n",
      "[I 2025-06-21 23:35:05,776] Trial 11 finished with value: 0.9590424592826838 and parameters: {'n_estimators': 384, 'max_depth': 8, 'learning_rate': 0.2856825331565266, 'subsample': 0.7064430983097565, 'colsample_bytree': 0.9191824571241586, 'gamma': 2.666737139204811}. Best is trial 11 with value: 0.9590424592826838.\n",
      "[I 2025-06-21 23:36:47,549] Trial 12 finished with value: 0.9611372219723959 and parameters: {'n_estimators': 407, 'max_depth': 8, 'learning_rate': 0.285667969812329, 'subsample': 0.7011219829912836, 'colsample_bytree': 0.8132989370821416, 'gamma': 1.90577988116043}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:38:23,340] Trial 13 finished with value: 0.9599093988067455 and parameters: {'n_estimators': 374, 'max_depth': 8, 'learning_rate': 0.29529325056135897, 'subsample': 0.7024098876960895, 'colsample_bytree': 0.8418886590494994, 'gamma': 1.9617581541981013}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:40:01,041] Trial 14 finished with value: 0.9603663049014738 and parameters: {'n_estimators': 357, 'max_depth': 8, 'learning_rate': 0.2925535460933392, 'subsample': 0.70285243282604, 'colsample_bytree': 0.7947793084268403, 'gamma': 1.5828714450357246}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:41:43,467] Trial 15 finished with value: 0.959238412608347 and parameters: {'n_estimators': 341, 'max_depth': 7, 'learning_rate': 0.21631675357932073, 'subsample': 0.5181849374041818, 'colsample_bytree': 0.6928786819266133, 'gamma': 1.3127344399259404}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:43:24,765] Trial 16 finished with value: 0.9590926647857746 and parameters: {'n_estimators': 425, 'max_depth': 9, 'learning_rate': 0.2953668113072907, 'subsample': 0.6949956846284241, 'colsample_bytree': 0.812998874069024, 'gamma': 1.9602074501319415}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:44:49,594] Trial 17 finished with value: 0.9582997120049683 and parameters: {'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.2622914767851292, 'subsample': 0.9887341110796684, 'colsample_bytree': 0.6824238281148998, 'gamma': 1.1830105896331213}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:46:51,231] Trial 18 finished with value: 0.9589935283577603 and parameters: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.21829689295806617, 'subsample': 0.6650222483113393, 'colsample_bytree': 0.8827455178806634, 'gamma': 1.6828069665058354}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:48:16,036] Trial 19 finished with value: 0.9565006090616084 and parameters: {'n_estimators': 358, 'max_depth': 9, 'learning_rate': 0.2584345331036129, 'subsample': 0.7475516655092583, 'colsample_bytree': 0.7532394379036842, 'gamma': 3.184932571699293}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:49:59,745] Trial 20 finished with value: 0.9404788262231267 and parameters: {'n_estimators': 240, 'max_depth': 7, 'learning_rate': 0.07869899148419243, 'subsample': 0.5563219869567897, 'colsample_bytree': 0.6759892813096761, 'gamma': 1.0615660272769067}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:51:37,209] Trial 21 finished with value: 0.9593742117108729 and parameters: {'n_estimators': 383, 'max_depth': 8, 'learning_rate': 0.2960630654426549, 'subsample': 0.7064150124656117, 'colsample_bytree': 0.8380737733939931, 'gamma': 2.1197289543711406}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:53:52,562] Trial 22 finished with value: 0.9576503789304649 and parameters: {'n_estimators': 407, 'max_depth': 8, 'learning_rate': 0.2755999737389612, 'subsample': 0.6607916967075013, 'colsample_bytree': 0.8482205940295495, 'gamma': 0.6924715065098701}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:55:33,275] Trial 23 finished with value: 0.9577944708837516 and parameters: {'n_estimators': 367, 'max_depth': 9, 'learning_rate': 0.2972425932173035, 'subsample': 0.7314698872392674, 'colsample_bytree': 0.9714965202157488, 'gamma': 1.7978150181357608}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:57:14,338] Trial 24 finished with value: 0.9597818397402985 and parameters: {'n_estimators': 331, 'max_depth': 8, 'learning_rate': 0.25427659975728256, 'subsample': 0.6621321245690666, 'colsample_bytree': 0.790431788554281, 'gamma': 1.600553247602346}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-21 23:58:58,495] Trial 25 finished with value: 0.9607233731587467 and parameters: {'n_estimators': 460, 'max_depth': 7, 'learning_rate': 0.22886066134540559, 'subsample': 0.5966824661219177, 'colsample_bytree': 0.8649419714800786, 'gamma': 2.3834074866360466}. Best is trial 12 with value: 0.9611372219723959.\n",
      "[I 2025-06-22 00:00:59,544] Trial 26 finished with value: 0.9625227042629465 and parameters: {'n_estimators': 493, 'max_depth': 6, 'learning_rate': 0.22899163208081902, 'subsample': 0.5862383593069921, 'colsample_bytree': 0.9546841341579957, 'gamma': 2.5804307433173714}. Best is trial 26 with value: 0.9625227042629465.\n",
      "[I 2025-06-22 00:03:05,027] Trial 27 finished with value: 0.9603974885569759 and parameters: {'n_estimators': 495, 'max_depth': 6, 'learning_rate': 0.1954572676800188, 'subsample': 0.5830273251127616, 'colsample_bytree': 0.9440740273445394, 'gamma': 3.046697805924243}. Best is trial 26 with value: 0.9625227042629465.\n",
      "[I 2025-06-22 00:04:51,168] Trial 28 finished with value: 0.9642915746436629 and parameters: {'n_estimators': 459, 'max_depth': 5, 'learning_rate': 0.22289718972125497, 'subsample': 0.5211614520390018, 'colsample_bytree': 0.8829213744714085, 'gamma': 2.4144960702109004}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:06:35,572] Trial 29 finished with value: 0.9598215973948794 and parameters: {'n_estimators': 495, 'max_depth': 5, 'learning_rate': 0.16491520960805023, 'subsample': 0.5251290356604174, 'colsample_bytree': 0.9419604732522951, 'gamma': 3.6219392573540605}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:08:10,493] Trial 30 finished with value: 0.9619498453142329 and parameters: {'n_estimators': 451, 'max_depth': 4, 'learning_rate': 0.19335435285186264, 'subsample': 0.5391515408259564, 'colsample_bytree': 0.894322238942013, 'gamma': 3.2482323833690847}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:09:44,193] Trial 31 finished with value: 0.9622848657713952 and parameters: {'n_estimators': 458, 'max_depth': 4, 'learning_rate': 0.19986528877751528, 'subsample': 0.5074653580594491, 'colsample_bytree': 0.8983779767224407, 'gamma': 3.2978142315901144}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:11:19,847] Trial 32 finished with value: 0.9616063044433174 and parameters: {'n_estimators': 457, 'max_depth': 4, 'learning_rate': 0.19505799990467215, 'subsample': 0.5035340036726109, 'colsample_bytree': 0.9014436948408405, 'gamma': 3.3231520370835703}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:12:53,136] Trial 33 finished with value: 0.9622970777244351 and parameters: {'n_estimators': 455, 'max_depth': 4, 'learning_rate': 0.2380333339067757, 'subsample': 0.5425243331489671, 'colsample_bytree': 0.9987776953157641, 'gamma': 4.007547289194568}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:14:14,076] Trial 34 finished with value: 0.961713442187239 and parameters: {'n_estimators': 422, 'max_depth': 3, 'learning_rate': 0.23678302064910314, 'subsample': 0.56033444736222, 'colsample_bytree': 0.9576239206075516, 'gamma': 4.163928427981448}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:16:01,460] Trial 35 finished with value: 0.9635576122606964 and parameters: {'n_estimators': 473, 'max_depth': 5, 'learning_rate': 0.213850305661371, 'subsample': 0.5928342854257149, 'colsample_bytree': 0.985174820636228, 'gamma': 2.8450959856688374}. Best is trial 28 with value: 0.9642915746436629.\n",
      "[I 2025-06-22 00:17:44,906] Trial 36 finished with value: 0.9645332198458998 and parameters: {'n_estimators': 478, 'max_depth': 5, 'learning_rate': 0.24624374866926696, 'subsample': 0.5935618872820965, 'colsample_bytree': 0.9915746129733698, 'gamma': 2.839930615243938}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:19:44,900] Trial 37 finished with value: 0.959487622395368 and parameters: {'n_estimators': 498, 'max_depth': 6, 'learning_rate': 0.1507232347917111, 'subsample': 0.5974736371629937, 'colsample_bytree': 0.9335990735206687, 'gamma': 2.921782931287308}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:21:36,743] Trial 38 finished with value: 0.9633800553615286 and parameters: {'n_estimators': 477, 'max_depth': 5, 'learning_rate': 0.2186827910724067, 'subsample': 0.5744714002358231, 'colsample_bytree': 0.974491781571514, 'gamma': 2.5868787782896923}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:23:28,271] Trial 39 finished with value: 0.9636402987761926 and parameters: {'n_estimators': 477, 'max_depth': 5, 'learning_rate': 0.21182024397911994, 'subsample': 0.6428518360693726, 'colsample_bytree': 0.972901002548814, 'gamma': 2.7571543456778578}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:25:29,388] Trial 40 finished with value: 0.962731196701321 and parameters: {'n_estimators': 475, 'max_depth': 5, 'learning_rate': 0.17799783845326356, 'subsample': 0.6484512378022353, 'colsample_bytree': 0.9965641995170192, 'gamma': 2.2144339231009758}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:27:20,455] Trial 41 finished with value: 0.9630957468698508 and parameters: {'n_estimators': 474, 'max_depth': 5, 'learning_rate': 0.21320536655628117, 'subsample': 0.620723224772401, 'colsample_bytree': 0.9702902881862027, 'gamma': 2.765334856168634}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:28:54,594] Trial 42 finished with value: 0.9613671460725339 and parameters: {'n_estimators': 429, 'max_depth': 5, 'learning_rate': 0.2500589489418122, 'subsample': 0.5757829487175612, 'colsample_bytree': 0.927132586390959, 'gamma': 3.685953365857461}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:30:50,546] Trial 43 finished with value: 0.9640814957271677 and parameters: {'n_estimators': 474, 'max_depth': 5, 'learning_rate': 0.21125850834065307, 'subsample': 0.6066876591856225, 'colsample_bytree': 0.9749992536430692, 'gamma': 2.4615364731991507}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:31:44,963] Trial 44 finished with value: 0.952289148611869 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.27333457708525183, 'subsample': 0.6029415668733018, 'colsample_bytree': 0.918657687967861, 'gamma': 2.8845365090055655}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:33:43,470] Trial 45 finished with value: 0.9611132908882961 and parameters: {'n_estimators': 412, 'max_depth': 6, 'learning_rate': 0.18429724551208151, 'subsample': 0.8293348876916091, 'colsample_bytree': 0.9802724327458036, 'gamma': 2.3363791502314424}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:35:10,554] Trial 46 finished with value: 0.9558087589438167 and parameters: {'n_estimators': 441, 'max_depth': 3, 'learning_rate': 0.16185604880284343, 'subsample': 0.6315042738900244, 'colsample_bytree': 0.9558487773075739, 'gamma': 2.487553896422995}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:37:14,810] Trial 47 finished with value: 0.9599456267981055 and parameters: {'n_estimators': 470, 'max_depth': 5, 'learning_rate': 0.1318761113078949, 'subsample': 0.6082743049186429, 'colsample_bytree': 0.9174562876754085, 'gamma': 2.1794778778236905}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:38:37,696] Trial 48 finished with value: 0.9443707151229287 and parameters: {'n_estimators': 283, 'max_depth': 5, 'learning_rate': 0.10918434659520906, 'subsample': 0.7866412087403791, 'colsample_bytree': 0.8779542719680976, 'gamma': 2.7629711670312536}. Best is trial 36 with value: 0.9645332198458998.\n",
      "[I 2025-06-22 00:40:08,118] Trial 49 finished with value: 0.9554041923868357 and parameters: {'n_estimators': 402, 'max_depth': 6, 'learning_rate': 0.24314716664532643, 'subsample': 0.5396641307674483, 'colsample_bytree': 0.9988461855810858, 'gamma': 4.708394748374923}. Best is trial 36 with value: 0.9645332198458998.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Optimisation terminée\n",
      " Meilleurs paramètres : {'n_estimators': 478, 'max_depth': 5, 'learning_rate': 0.24624374866926696, 'subsample': 0.5935618872820965, 'colsample_bytree': 0.9915746129733698, 'gamma': 2.839930615243938}\n",
      "  Entraînement du modèle avec SMOTE\n",
      "  Préprocesseur ajusté\n",
      "   • Après SMOTE : 66405 échantillons\n",
      "   • Classifieur entraîné\n",
      " Pipeline d’inférence prêt\n",
      "Sauvegarde du pipeline et de l’encodeur dans /content/drive/MyDrive/final_travail_Attrition/model\n",
      " Sauvegarde terminée\n",
      "\n",
      "📊 Évaluation du modèle sur l'ensemble d'entraînement complet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.99      0.98      0.99     22135\n",
      "      Medium       0.96      0.97      0.96     17767\n",
      "        High       0.99      0.98      0.98     19696\n",
      "\n",
      "    accuracy                           0.98     59598\n",
      "   macro avg       0.98      0.98      0.98     59598\n",
      "weighted avg       0.98      0.98      0.98     59598\n",
      "\n",
      "\n",
      "✅ Résultats de performance sauvegardés dans : /content/drive/MyDrive/final_travail_Attrition/model/resultats_xgboost_optuna.csv\n",
      "Tout est terminé !\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "import matplotlib # Import the matplotlib library\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "print(\"joblib:\", joblib.__version__)\n",
    "print(\"optuna:\", optuna.__version__)\n",
    "import sklearn # Import the sklearn library\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "import xgboost # Import the xgboost library\n",
    "print(\"xgboost:\", xgboost.__version__)\n",
    "import imblearn # Import the imblearn library\n",
    "print(\"imblearn:\", imblearn.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCGkiYcJ9SyI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750553444484,
     "user_tz": -60,
     "elapsed": 10,
     "user": {
      "displayName": "nedia chaieb",
      "userId": "02418120950381189238"
     }
    },
    "outputId": "9075d6c6-05a8-41fa-e029-3da4edc76cd3"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pandas: 2.2.2\n",
      "numpy: 2.0.2\n",
      "matplotlib: 3.10.0\n",
      "joblib: 1.5.1\n",
      "optuna: 4.4.0\n",
      "scikit-learn: 1.6.1\n",
      "xgboost: 2.1.4\n",
      "imblearn: 0.13.0\n"
     ]
    }
   ]
  }
 ]
}
